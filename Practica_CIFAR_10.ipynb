{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica CIFAR-10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Hv3czYrqFR",
        "colab_type": "text"
      },
      "source": [
        "# Clasificador de im치genes CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Nh2-sdrUd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% load_ext autoreload\n",
        "% autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FETPRPEBsRSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b853a1a2-a704-42f9-b080-c96d423a1f14"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN8lTZuhsbE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The data, split between train, val and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_flip=np.flip(x_train,axis=2)\n",
        "x_train_flip=x_train_flip.reshape(-1,3072)\n",
        "x_train=x_train.reshape(-1,3072)\n",
        "x_test=x_test.reshape(-1,3072)\n",
        "x_train=np.vstack([x_train,x_train_flip])\n",
        "y_train=np.vstack([y_train, y_train])\n",
        "scaler=StandardScaler()\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.2, stratify=y_train)\n",
        "scaler.fit(x_train)\n",
        "x_train_std=scaler.transform(x_train)\n",
        "x_val_std=scaler.transform(x_val)\n",
        "x_test_std=scaler.transform(x_test)\n",
        "\n",
        "clases=[\"airplane\",\n",
        "        \"automobile\",\t\t\t\t\t\t\t\n",
        "        \"bird\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"cat\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"deer\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"dog\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"frog\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"horse\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"ship\",\t\t\t\t\t\t\t\t\t\t\n",
        "        \"truck\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG7qRqyNu-El",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4efad6fe-7c9d-43b0-a852-3d4349cb3277"
      },
      "source": [
        "# Chequeamos que los subsets queden correctamente estratificados.\n",
        "np.unique(y_train,return_counts=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              " array([8000, 8000, 8000, 8000, 8000, 8000, 8000, 8000, 8000, 8000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKibCZzr1Lma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec55245b-5b53-407f-d28a-4e18639b97ea"
      },
      "source": [
        "x_train_std[:,10].std()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr9Y_HRssled",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funci칩n para graficar las im치genes\n",
        "def plot_img(imageID,x,y):\n",
        "  plt.figure(figsize=[2,2])\n",
        "  plt.imshow(x[imageID].reshape(32,32,3))\n",
        "  plt.show()\n",
        "  print(f'Clase: {clases[y[imageID][0]]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5TfgFOAsvZH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "effcfebe-22d8-466a-c1cd-5f53d3843c04"
      },
      "source": [
        "plot_img(73890,x_train,y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Clase: truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs67T1y_tFT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a5d48bd6-5598-4287-a122-dade946320d5"
      },
      "source": [
        "from keras.layers import Dense, Dropout,Activation\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpointer=ModelCheckpoint(\"best_weights.hdf5\",monitor=\"val_acc\",save_best_only=True,verbose=True)\n",
        "stopper=EarlyStopping(monitor=\"val_loss\",patience=10,verbose=True)\n",
        "model=Sequential()\n",
        "model.add(Dense(200,activation=\"linear\",input_shape=(3072,)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(200,activation=\"linear\"))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 200)               614600    \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                2010      \n",
            "=================================================================\n",
            "Total params: 656,810\n",
            "Trainable params: 656,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmKy8-hPxcyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "909f4a91-8171-4be7-c114-a665b5b77225"
      },
      "source": [
        "model.fit(x=x_train_std,y=y_train,validation_data=(x_val_std,y_val),batch_size=256,epochs=200,callbacks=[checkpointer])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/200\n",
            "80000/80000 [==============================] - 4s 54us/step - loss: 2.1449 - acc: 0.4244 - val_loss: 1.9263 - val_acc: 0.4668\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.46680, saving model to best_weights.hdf5\n",
            "Epoch 2/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.7825 - acc: 0.4977 - val_loss: 1.7451 - val_acc: 0.4956\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.46680 to 0.49565, saving model to best_weights.hdf5\n",
            "Epoch 3/200\n",
            "80000/80000 [==============================] - 3s 44us/step - loss: 1.6198 - acc: 0.5274 - val_loss: 1.6406 - val_acc: 0.5132\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.49565 to 0.51320, saving model to best_weights.hdf5\n",
            "Epoch 4/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.5344 - acc: 0.5443 - val_loss: 1.5956 - val_acc: 0.5166\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.51320 to 0.51660, saving model to best_weights.hdf5\n",
            "Epoch 5/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.4841 - acc: 0.5569 - val_loss: 1.5600 - val_acc: 0.5268\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.51660 to 0.52680, saving model to best_weights.hdf5\n",
            "Epoch 6/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.4504 - acc: 0.5669 - val_loss: 1.5469 - val_acc: 0.5330\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.52680 to 0.53300, saving model to best_weights.hdf5\n",
            "Epoch 7/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.4288 - acc: 0.5738 - val_loss: 1.5593 - val_acc: 0.5280\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.53300\n",
            "Epoch 8/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.4138 - acc: 0.5777 - val_loss: 1.5124 - val_acc: 0.5420\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.53300 to 0.54200, saving model to best_weights.hdf5\n",
            "Epoch 9/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3985 - acc: 0.5848 - val_loss: 1.5109 - val_acc: 0.5484\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.54200 to 0.54845, saving model to best_weights.hdf5\n",
            "Epoch 10/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3848 - acc: 0.5902 - val_loss: 1.5191 - val_acc: 0.5470\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.54845\n",
            "Epoch 11/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3716 - acc: 0.5934 - val_loss: 1.4945 - val_acc: 0.5528\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.54845 to 0.55280, saving model to best_weights.hdf5\n",
            "Epoch 12/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3623 - acc: 0.5991 - val_loss: 1.5193 - val_acc: 0.5486\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.55280\n",
            "Epoch 13/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3561 - acc: 0.6018 - val_loss: 1.4897 - val_acc: 0.5556\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.55280 to 0.55565, saving model to best_weights.hdf5\n",
            "Epoch 14/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.3419 - acc: 0.6067 - val_loss: 1.5114 - val_acc: 0.5455\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55565\n",
            "Epoch 15/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3371 - acc: 0.6100 - val_loss: 1.5049 - val_acc: 0.5527\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55565\n",
            "Epoch 16/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3285 - acc: 0.6122 - val_loss: 1.5008 - val_acc: 0.5501\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.55565\n",
            "Epoch 17/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3249 - acc: 0.6137 - val_loss: 1.4982 - val_acc: 0.5530\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.55565\n",
            "Epoch 18/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3140 - acc: 0.6178 - val_loss: 1.4944 - val_acc: 0.5585\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.55565 to 0.55845, saving model to best_weights.hdf5\n",
            "Epoch 19/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3050 - acc: 0.6205 - val_loss: 1.4931 - val_acc: 0.5613\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.55845 to 0.56125, saving model to best_weights.hdf5\n",
            "Epoch 20/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.3027 - acc: 0.6223 - val_loss: 1.4762 - val_acc: 0.5654\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.56125 to 0.56540, saving model to best_weights.hdf5\n",
            "Epoch 21/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2958 - acc: 0.6230 - val_loss: 1.5115 - val_acc: 0.5573\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.56540\n",
            "Epoch 22/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2939 - acc: 0.6266 - val_loss: 1.4725 - val_acc: 0.5635\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.56540\n",
            "Epoch 23/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.2806 - acc: 0.6329 - val_loss: 1.4704 - val_acc: 0.5659\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.56540 to 0.56595, saving model to best_weights.hdf5\n",
            "Epoch 24/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2770 - acc: 0.6320 - val_loss: 1.4823 - val_acc: 0.5678\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.56595 to 0.56785, saving model to best_weights.hdf5\n",
            "Epoch 25/200\n",
            "80000/80000 [==============================] - 4s 44us/step - loss: 1.2734 - acc: 0.6354 - val_loss: 1.4931 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.56785\n",
            "Epoch 26/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2699 - acc: 0.6357 - val_loss: 1.4631 - val_acc: 0.5739\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.56785 to 0.57390, saving model to best_weights.hdf5\n",
            "Epoch 27/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2657 - acc: 0.6388 - val_loss: 1.4969 - val_acc: 0.5617\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.57390\n",
            "Epoch 28/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2625 - acc: 0.6422 - val_loss: 1.5000 - val_acc: 0.5625\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.57390\n",
            "Epoch 29/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.2583 - acc: 0.6419 - val_loss: 1.4823 - val_acc: 0.5674\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.57390\n",
            "Epoch 30/200\n",
            "80000/80000 [==============================] - 3s 43us/step - loss: 1.2512 - acc: 0.6442 - val_loss: 1.4961 - val_acc: 0.5672\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.57390\n",
            "Epoch 31/200\n",
            "80000/80000 [==============================] - 3s 42us/step - loss: 1.2510 - acc: 0.6464 - val_loss: 1.4820 - val_acc: 0.5659\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.57390\n",
            "Epoch 32/200\n",
            "21248/80000 [======>.......................] - ETA: 2s - loss: 1.2051 - acc: 0.6624"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-8eff8c958084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                     'pass shuffle=\"batch\".')\n\u001b[1;32m    199\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \"\"\"\n\u001b[1;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3502\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m     \"\"\"\n\u001b[0;32m-> 3385\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3386\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz6NeOv30cMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"best_weights.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQOyBek0lLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa0d4558-e346-4f8c-fd18-677082de101b"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 150us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.735667244720459, 0.7606]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_The6Sd6L8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "003095fa-8e37-4173-8768-f59d6f40fad8"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdXhV-6DK5wn",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo Red Con Regularizaci칩n L2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l77t-4ha9rRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout,Activation,Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpointer=ModelCheckpoint(\"best_weights.hdf5\",monitor=\"val_acc\",save_best_only=True,verbose=True)\n",
        "stopper=EarlyStopping(monitor=\"val_loss\",patience=10,verbose=True)\n",
        "reg=l2(l=0.001)\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Dense(200,activation=\"relu\",kernel_regularizer=reg,bias_regularizer=reg, input_shape=(3072,)))\n",
        "model.add(Dense(200,activation=\"relu\",kernel_regularizer=reg,bias_regularizer=reg))\n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvJ_fhwQK_gu",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo Red Conv 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZxYcYM-K5KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout,Activation,Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpointer=ModelCheckpoint(\"best_weights.hdf5\",monitor=\"val_acc\",save_best_only=True,verbose=True)\n",
        "stopper=EarlyStopping(monitor=\"val_loss\",patience=10,verbose=True)\n",
        "reg=l2(l=0.01)\n",
        "model=Sequential()\n",
        "model.add(Conv2D(64,3,input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64,3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}